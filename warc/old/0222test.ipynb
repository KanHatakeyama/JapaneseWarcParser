{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.file_utils import download_file, decompress_gz,make_dir\n",
    "import glob\n",
    "from warcio.archiveiterator import ArchiveIterator\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from src.parse_warc import extract_japanese_from_warc\n",
    "\n",
    "import json\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "from ja_sentence_segmenter.common.pipeline import make_pipeline\n",
    "from ja_sentence_segmenter.concatenate.simple_concatenator import concatenate_matching\n",
    "from ja_sentence_segmenter.normalize.neologd_normalizer import normalize\n",
    "from ja_sentence_segmenter.split.simple_splitter import split_newline, split_punctuation\n",
    "\n",
    "split_punc2 = functools.partial(split_punctuation, punctuations=r\"。!?\")\n",
    "concat_tail_te = functools.partial(concatenate_matching, former_matching_rule=r\"^(?P<result>.+)(て)$\", remove_former_matched=False)\n",
    "segmenter = make_pipeline(normalize, split_newline, concat_tail_te, split_punc2)\n",
    "\n",
    "text1 = \"\"\"\n",
    "私は「あなたの思いに答えられない。他を当たってほしい。」と言われました！呆然として\n",
    "その場にたたずむしかありませんでしたそれでも私は信じたい！\n",
    "\"\"\"\n",
    "text1='本題 トップページ こんにちは｡メールでもOKです。'\n",
    "\n",
    "print(list(segmenter(text1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path_list=glob.glob('data/gz/*.gz')\n",
    "len(json_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"data/jap_dump/crawl-data_CC-MAIN-2023-50_segments_1700679099281.67_warc_CC-MAIN-20231128083443-20231128113443-00000.warc_jap.gz.gz\"\n",
    "# gzipで圧縮されたJSONファイルを読み込み\n",
    "with gzip.open(path, 'rt', encoding='utf-8') as f:\n",
    "    data_loaded = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm\n",
    "import sentencepiece\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "class PerplexityChecker:\n",
    "    def __init__(self, arpa_path, sp_path):\n",
    "        self.ken_model = kenlm.LanguageModel(arpa_path)\n",
    "        self.sp = sentencepiece.SentencePieceProcessor()\n",
    "        self.sp.load(sp_path)\n",
    "\n",
    "    def __call__(self, inp):\n",
    "        text = unicodedata.normalize('NFD', inp)\n",
    "        toks = self.sp.encode(text, out_type=str)\n",
    "        sentence = \" \".join(toks)\n",
    "        ppl = self.ken_model.perplexity(sentence)\n",
    "        return ppl\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker=PerplexityChecker(\"data/lm_sp/ja.arpa.bin\",\n",
    "                          \"data/lm_sp/ja.sp.model\",\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record=data_loaded[17]\n",
    "\n",
    "new_lines=[]\n",
    "current_line=\"\"\n",
    "#old_line=\"\"\n",
    "dup_n_threshold=100\n",
    "for line in record[\"text\"]:\n",
    "    line=line[0].strip()\n",
    "    #if line in new_lines:\n",
    "    if line in new_lines[-dup_n_threshold:]:\n",
    "        #print(\"dup:\",line)\n",
    "        continue\n",
    "    old_line=line\n",
    "    print(line)\n",
    "    joint_text=current_line+line\n",
    "    sep_text=current_line+\"\\n\"+line\n",
    "\n",
    "    joint_ppl=checker(joint_text)\n",
    "    sep_ppl=checker(sep_text)\n",
    "    \n",
    "    if joint_ppl<sep_ppl:\n",
    "        current_line=joint_text\n",
    "    else:\n",
    "        new_lines.append(current_line)\n",
    "        current_line=line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=\"\"\"入力、または「\n",
    "GREE\"\"\"\n",
    "t2=\"\"\"入力、または「GREE\"\"\"\n",
    "\n",
    "checker(t1),checker(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"お問い合わせ\"==\"お問い合わせ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qcl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
