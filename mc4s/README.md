# mc4データセットをクリーニングするスクリプト
- Huggingfaceのdatasetsから読み込み
    - 各レコードごとに
        - 正規化
        - 文章クリーニング
        - 機械学習による選別(教師有り)
        - (記事内容のクラス分け(教師なし) : 精度が悪いので無し)
        - 出力

# 実行方法
```
python mc4_cleaner.py
```
- 備考
    - はじめに､[clean_dev.ipynb](clean_dev.ipynb)でfasttextのモデルを作ります.
    - 100 it/sほどの速度で動きます｡
        - 87337884 recordあるので､240 hrほどかかりそうです｡
    - 並列化､高速化の余地は沢山あると思います
        - mc4 datasetを一時ファイルとして､iteratorで読み込んでるので､ここが明らかな律速段階の一つです｡
